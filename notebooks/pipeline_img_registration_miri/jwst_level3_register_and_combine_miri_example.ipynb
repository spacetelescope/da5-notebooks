{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Registration and Combination using the JWST Level 3 Pipeline - MIRI example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 3 image (Image3, calwebb_image3) processing is intended for combining the calibrated data from multiple exposures (e.g., a dither or mosaic pattern) into a single distortion corrected product. Before being combined, the exposures receive additional corrections for the purpose of astrometric alignment, background matching, and outlier rejection. \n",
    "\n",
    "> **Inputs**: The inputs to calwebb_image3 will usually be in the form of an association (ASN) file that lists multiple associated 2D calibrated exposures to be processed and combined into a single product. The individual exposures should be calibrated (\"cal\") from calwebb_image2 processing. It is also possible use a single \"cal\" file as input, in which case only the resample and source_catalog steps will be applied.\n",
    "\n",
    "> **Outputs**: A resampled/rectified 2D image product with suffix \"i2d\" is created, containing the rectified single exposure or the rectified and combined association of exposures (the direct output of the resample step). A source catalog produced from the \"i2d\" product is saved as an ASCII file in \"ecsv\" format, with a suffix of \"cat\". If the outlier_detection step is applied, a new version of each input calibrated exposure product is created, which contains a DQ array that has been updated to flag pixels detected as outliers. This updated product is known as a CR-flagged product and the file is identified by including the association candidate ID in the original input \"cal\" file name and changing the suffix to \"crf\".\n",
    "    \n",
    "\n",
    "Level 3 pipeline steps:\n",
    "\n",
    "**Tweakreg** (jwst.tweakreg, tweakreg_step, TweakRegStep)\n",
    "\n",
    "**Sky Match** (jwst.skymatch, skymatch_step, SkyMatchStep)\n",
    "\n",
    "**Outlier Detection** (jwst.outlier_detection, outlier_detection_step, OutlierDetectionStep)\n",
    "\n",
    "**Resample** (jwst.resample, resample_step, ResampleStep)\n",
    "\n",
    "**Source Catalog** (jwst.source_catalog, source_catalog_step, SourceCatalogStep)\n",
    "\n",
    "(for more information on individual steps see: https://jwst-pipeline.readthedocs.io/en/latest/jwst/package_index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents:\n",
    "> * [Resources and Documentation](#resources)\n",
    "> * [Create Association table](#association)\n",
    "> * [Using Configuration Files](#pipeline_configs)\n",
    "> * [Run Pipeline with Configuration Files](#pipeline_with_cfgs)\n",
    "> * [Run Pipeline with Parameters Set Programmatically](#pipeline_no_configs)\n",
    "> * [Run Individual Steps with Configuration Files](#steps_with_config_files)\n",
    "> * [Run Individual Steps with Parameters Set Programmatically](#steps_no_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id='resources'></a>\n",
    "## 1. Resources and Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several different places to find information on installing and running the pipeline. This notebook will give a shortened description of the steps pulled from the detailed pipeline information pages, but to find more in-depth instructions use the links below. \n",
    "\n",
    ">1. JDox: https://jwst-docs.stsci.edu/display/JDAT/JWST+Data+Reduction+Pipeline\n",
    ">2. Installation page: http://astroconda.readthedocs.io/en/latest/releases.html#pipeline-install\n",
    ">3. Detailed pipeline information: https://jwst-pipeline.readthedocs.io/en/latest/jwst/introduction.html\n",
    ">4. Help Desk (click on Pipeline Support): https://stsci.service-now.com/jwst?id=sc_category\n",
    ">5. GitHub README installation instructions: https://github.com/spacetelescope/jwst/blob/master/README.md\n",
    "\n",
    "\n",
    "If this is your first time trying to run the pipeline from a jupyter notebook, you need to install the jupyter notebook in your pipeline environment:\n",
    ">1. In a new terminal, change the directory to your working directory, terminal command: cd [your working directory]\n",
    ">2. Terminal command: source activate jwst_dev\n",
    "(or whatever your environment name for the pipeline is)\n",
    ">3. Terminal command: conda install jupyter\n",
    ">4. Terminal command: jupyter notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must define environment variables for the CRDS server. This is necessary if you are not on the STScI internal network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu/'\n",
    "os.environ['CRDS_PATH'] = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.visualization import LogStretch, ImageNormalize, ManualInterval\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from jwst import datamodels\n",
    "from jwst.pipeline import Image3Pipeline\n",
    "# from jwst.associations.asn_from_list import asn_from_list  # perhaps can be done in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import individual pipeline steps\n",
    "from jwst.tweakreg import tweakreg_step\n",
    "from jwst.skymatch import skymatch_step\n",
    "from jwst.outlier_detection import outlier_detection_step\n",
    "from jwst.resample import resample_step\n",
    "from jwst.source_catalog import source_catalog_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example dataset to be used with this notebook is present in our Box repository. The cells below download:\n",
    "\n",
    "1. The association file to be used as input to the pipeline\n",
    "2. The fits files listed in the association file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_path = 'https://stsci.box.com/shared/static/'\n",
    "\n",
    "association_file_link = '2vlo7yqk00wmpu8x32ipg127i8lynpr2.json'\n",
    "fits_box_links = ['1voplv0ooacf0eb0v8ebx6kbm8udxp56.fits',\n",
    "                  'gqqjnx560jq8a71nbwsumh1nrfdz30ez.fits',\n",
    "                  'hmvf8fykpkliyin89swtbfzul28nisqz.fits',\n",
    "                  '9tqp5v8sfwwmgrc639000nvcs7inzfxg.fits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url):\n",
    "    \"\"\"Download into the current working directory the\n",
    "    file from Box given the direct URL\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        URL to the file to be downloaded\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    download_filename : str\n",
    "        Name of the downloaded file\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(\"Wrong URL - {}\".format(url))\n",
    "    download_filename = response.headers['Content-Disposition'].split('\"')[1]\n",
    "    with open(download_filename, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    return download_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download association file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "association_url = os.path.join(box_path, association_file_link)\n",
    "association_file = download_file(association_url)\n",
    "print(association_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download FITS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a copy of the data used in this notebook from the Box repository\n",
    "for boxfile in fits_box_links:\n",
    "    file_url = os.path.join(box_path, boxfile)\n",
    "    fits_file = download_file(file_url)\n",
    "    print(\"Downloading {}\".format(fits_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id='association'></a>\n",
    "## 2. Create an Association Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An association table is a **json** file that should contain all of the files to be combined in a single mosaic. Files that cannot be combined (e.g. NIRCam shortwave and longwave data) must be placed in separate association tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example association table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{\n",
    "    \"asn_type\": \"None\",\n",
    "    \"asn_rule\": \"DMS_Level3_Base\",\n",
    "    \"version_id\": null,\n",
    "    \"code_version\": \"0.10.1a.dev241\",\n",
    "    \"degraded_status\": \"No known degraded exposures in association.\",\n",
    "    \"program\": \"noprogram\",\n",
    "    \"constraints\": \"No constraints\",\n",
    "    \"asn_id\": \"a3001\",\n",
    "    \"target\": \"none\",\n",
    "    \"asn_pool\": \"none\",\n",
    "    \"products\": [\n",
    "        {\n",
    "            \"name\": \"jw10002_short\",\n",
    "            \"members\": [\n",
    "                {\n",
    "                    \"expname\": \"jw10002001001_01101_00001_nrcb1_cal.fits\",\n",
    "                    \"exptype\": \"science\"\n",
    "                },\n",
    "                {\n",
    "                    \"expname\": \"jw10002001001_01101_00001_nrcb2_cal.fits\",\n",
    "                    \"exptype\": \"science\"\n",
    "                },\n",
    "                {\n",
    "                    \"expname\": \"jw10002001001_01101_00001_nrcb3_cal.fits\",\n",
    "                    \"exptype\": \"science\"\n",
    "                },\n",
    "                {\n",
    "                    \"expname\": \"jw10002001001_01101_00001_nrcb4_cal.fits\",\n",
    "                    \"exptype\": \"science\"\n",
    "                },\n",
    "                {\n",
    "                    \"expname\": \"jw10002001001_01102_00001_nrcb1_cal.fits\",\n",
    "                    \"exptype\": \"science\"\n",
    "                },\n",
    "                {\n",
    "                    \"expname\": \"jw10002001001_01102_00001_nrcb2_cal.fits\",\n",
    "                    \"exptype\": \"science\"\n",
    "                },\n",
    "                {\n",
    "                    \"expname\": \"jw10002001001_01102_00001_nrcb3_cal.fits\",\n",
    "                    \"exptype\": \"science\"\n",
    "                },\n",
    "                {\n",
    "                    \"expname\": \"jw10002001001_01102_00001_nrcb4_cal.fits\",\n",
    "                    \"exptype\": \"science\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pipeline_configs'></a>\n",
    "## 3. Using Configuration Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration files are optional inputs for each step of the pipeline, as well as for the pipeline itself. These files list step-specific parameters, and can also be used to control which steps are run as part of the pipeline.\n",
    "\n",
    "You can get the full compliment of configuration files using the `collect_pipeline_cfgs` convenience function from the command line:\n",
    "\n",
    ">`$ collect_pipeline_cfgs ./`\n",
    "\n",
    "This creates a copy of all configuration files, for all steps and all JWST Instruments. Note that default parameters in the config files are not necessarily optimized for any particular instrument. \n",
    "\n",
    "Each of these configuration files can be customized to control pipeline behavior. For example, the configuration file for the Level 3 imaging pipeline is called **calwebb_image3.cfg** and contains a list (not necessarily in order) of the steps run as part of the Level 3 imaging pipeline.\n",
    "\n",
    "\n",
    "    name = \"Image3Pipeline\"\n",
    "    class = \"jwst.pipeline.Image3Pipeline\"\n",
    "\n",
    "        [steps]\n",
    "          [[tweakreg]]\n",
    "            config_file = tweakreg.cfg\n",
    "            skip = True\n",
    "          [[skymatch]]\n",
    "            config_file = skymatch.cfg\n",
    "          [[outlier_detection]]\n",
    "            config_file = outlier_detection.cfg\n",
    "          [[resample]]\n",
    "            config_file = resample.cfg\n",
    "          [[source_catalog]]\n",
    "            config_file = source_catalog.cfg\n",
    "            save_results = true\n",
    "        \n",
    "In this example, the ***tweakreg*** step will be skipped (`skip = True`), and the output from the ***source_catalog*** step will be saved (`save_results = True`).\n",
    "\n",
    "Note that **calwebb_image3.cfg** lists a configuration file for each pipeline step. You can customize a particular pipeline step by editing the parameters in its configuration file. For example, the source catalog configuration file, shown below, contains details on the kernel size and FWHM, as well as the signal to noise threshold to use in the identification of sources in the final combined image. \n",
    "\n",
    "\n",
    "    name = \"source_catalog\"\n",
    "    class = \"jwst.source_catalog.SourceCatalogStep\"\n",
    "\n",
    "    kernel_fwhm = 3.\n",
    "    kernel_xsize = 5.\n",
    "    kernel_ysize = 5.\n",
    "    snr_threshold = 3.\n",
    "    npixels = 50\n",
    "    deblend = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Running the pipeline on MIRI data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset being used in this notebook is a set of four files, each with 5 point sources, two files each at two different dither positions. The files can be combined by running them through the pipeline. The final output catalog has one extra position listed, if everything is run with defaults. The files can be found at https://stsci.box.com/s/to6mcfmyap8kn7z9ordmcyb1dcbh1ps2. This repository also includes rate files (output of calwebb_detector1) and the cal files (output of calwebb_image2) as well as the files used to create the simulations in case those are helpful.\n",
    "\n",
    "The association file is 'det_dithered_5stars.json' and has the following content:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{\n",
    "    \"asn_type\": \"None\",\n",
    "    \"code_version\": \"0.9.19\",\n",
    "    \"asn_id\": \"a3001\",\n",
    "    \"products\": [\n",
    "        {\n",
    "            \"name\": \"det_dithered_5stars_tweak.fits\",\n",
    "            \"members\": [\n",
    "                {\n",
    "                    \"expname\": \"det_image_1_MIRIMAGE_F770Wexp1_5stars_cal.fits\",\n",
    "                    \"exptype\": \"science\"\n",
    "                },\n",
    "                {\n",
    "                    \"expname\": \"det_image_1_MIRIMAGE_F770Wexp2_5stars_cal.fits\",\n",
    "                    \"exptype\": \"science\"\n",
    "                },\n",
    "                {\n",
    "                    \"expname\": \"det_image_2_MIRIMAGE_F770Wexp1_5stars_cal.fits\",\n",
    "                    \"exptype\": \"science\"\n",
    "                },\n",
    "                {\n",
    "                    \"expname\": \"det_image_2_MIRIMAGE_F770Wexp2_5stars_cal.fits\",\n",
    "                    \"exptype\": \"science\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"asn_pool\": \"none\",\n",
    "    \"version_id\": null,\n",
    "    \"asn_rule\": \"DMS_Level3_Base\",\n",
    "    \"degraded_status\": \"No known degraded exposures in association.\",\n",
    "    \"program\": \"noprogram\",\n",
    "    \"constraints\": \"No constraints\",\n",
    "    \"target\": \"none\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined image is exported as: det_dithered_5stars_tweak_i2d.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"pipeline_with_cfgs\"></a>\n",
    "## 4. Run Pipeline with Configuration Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have edited the configuration files to customize the Level 3 pipeline, the command below will run the pipeline.\n",
    "\n",
    "This will generate a final source catalog ***cat.ecsv***, a final 2D image ***i2d.fits***, individual exposures with DQ array flagged for outliers ***crf.fits***, and blot images from the outlier detection step ***blot.fits***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Image3Pipeline.call(association_file, config_file='calwebb_image3.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output combined image\n",
    "combined_image_file = 'det_dithered_5stars_tweak_i2d.fits'\n",
    "combined_image = fits.getdata(combined_image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "norm = ImageNormalize(combined_image, interval=ManualInterval(vmin=-25, vmax=25), stretch=LogStretch())\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "im = ax.imshow(combined_image, origin='lower', norm=norm)\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"pipeline_no_configs\"></a>\n",
    "## 5. Run Pipeline with Parameters Set Programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run the pipeline without relying on configuration files by setting parameters programmatically, and relying on the defaults in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = Image3Pipeline()\n",
    "\n",
    "# You can skip steps and change parameter values\n",
    "m.tweakreg.skip = False\n",
    "m.source_catalog.snr_threshold = 10\n",
    "# run the pipeline with these parameters\n",
    "m.run(association_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_image_file = 'det_dithered_5stars_tweak_i2d.fits' ## need to load data gain\n",
    "combined_image = fits.getdata(combined_image_file) ## need to load data again\n",
    "norm = ImageNormalize(combined_image, interval=ManualInterval(vmin=-25, vmax=25), stretch=LogStretch())\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "im = ax.imshow(combined_image, origin='lower', norm=norm)\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"steps_with_config_files\"></a>\n",
    "## 6. Run Individual Steps with Configuration Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = tweakreg_step.TweakRegStep.call(association_file, config_file='tweakreg.cfg')\n",
    "m = skymatch_step.SkyMatchStep.call(m, config_file='skymatch.cfg')\n",
    "m = outlier_detection_step.OutlierDetectionStep.call(m, config_file='outlier_detection.cfg')\n",
    "m = resample_step.ResampleStep.call(m, config_file='resample.cfg', output_file='jw10002_short_step_by_step_i2d.fits')\n",
    "m = source_catalog_step.SourceCatalogStep.call(m, config_file='source_catalog.cfg', output_file='jw10002_short_step_by_step_cat.ecsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_image_file = 'det_dithered_5stars_tweak_i2d.fits' ## need to load data gain\n",
    "combined_image = fits.getdata(combined_image_file) ## need to load data again\n",
    "norm = ImageNormalize(combined_image, interval=ManualInterval(vmin=-25, vmax=25), stretch=LogStretch())\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "im = ax.imshow(combined_image, origin='lower', norm=norm)\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
